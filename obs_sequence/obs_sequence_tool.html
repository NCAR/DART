<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
          "http://www.w3.org/TR/html4/strict.dtd">
<HTML>
<HEAD>
<TITLE>PROGRAM obs_sequence_tool</TITLE>
<link rel="stylesheet" type="text/css" href="../doc/html/doc.css" />
<link href="../doc/images/dart.ico" rel="shortcut icon" />
</HEAD>
<BODY>
<A NAME="TOP"></A>

<H1>PROGRAM <em class=program>obs_sequence_tool</em></H1>

<table border=0 summary="" cellpadding=5>
<tr>
    <td valign=middle>
    <img src="../doc/images/Dartboard7.png" alt="DART project logo" height=70 />
    </td>
    <td>
       <P>Jump to <a href="../index.html">DART Documentation Main Index</a><br />
          <small><small>version information for this file: <br />
          <!-- version tag follows, do not edit -->
          $Id$</small></small>
       </P></td>
</tr>
</table>

<A HREF="#Namelist">NAMELIST</A> /
<A HREF="#Examples">EXAMPLES</A> /
<A HREF="#Building">BUILDING</A> /
<A HREF="#Discussion">DISCUSSION</A> /
<A HREF="#FAQ">FAQ</A> /
<A HREF="#FilesUsed">FILES</A> /
<A HREF="#References">REFERENCES</A> /
<A HREF="#Errors">ERRORS</A> /
<A HREF="#FuturePlans">PLANS</A> /
<A HREF="#Legalese">TERMS OF USE</A>

<H2>Overview</H2>

<P>
DART observation sequence files are stored in a proprietary format.
This tool makes it easier to manipulate these files, allowing the user
to subset or combine one or more files into a single output file.
</P>

<P>
The tool has many options
to select subsets of observations by time, type, data value, and location.
The tool also allows the contents of observations to be
changed by subsetting and/or reordering the copies and qc entries.
Files with equivalent data but with different metadata labels 
(e.g. 'NCEP QC' vs. 'QC') can now be merged as well.  
The tool can be run without creating an output file, only printing 
a summary of the counts of each observation type in the input files,
and it can be used to convert from binary to ASCII and back.
</P>

<P>
The actions of the <em class=code>obs_sequence_tool</em> program
are controlled by a Fortran namelist, read from a file named
<em class=file>input.nml</em> in the current directory.  A detailed
description of each namelist item is described in the
<a href="#Namelist">namelist section</a> below.
</P>

<P>
The <a href="#Examples">examples section</a> of this document below
has extensive examples of common usages for this tool.
Below that are more details about DART observation sequence files, the
structure of individual observations, and general background information.
</P>

<!--==================================================================-->
<!--=================== DESCRIPTION OF A NAMELIST ====================-->
<!--==================================================================-->

<A NAME="Namelist"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>NAMELIST</H2>
<P>
This namelist is read from the file <em class=file>input.nml</em>.
Namelists start with an ampersand
'&amp;' and terminate with a slash '/'.
Character strings that contain a '/' must be
enclosed in quotes to prevent them from 
prematurely terminating the namelist.
</P>

<div class=namelist>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq         = '',
   filename_seq_list    = '',
   filename_out         = 'obs_seq.processed',
   num_input_files      = 0,
   first_obs_days       = -1,
   first_obs_seconds    = -1,
   last_obs_days        = -1,
   last_obs_seconds     = -1,
   obs_types            = '',
   keep_types           = .true.,
   min_lat              =  -90.0,
   max_lat              =   90.0,
   min_lon              =    0.0,
   max_lon              =  360.0,
   print_only           = .false.,
   gregorian_cal        = .true.,
   edit_copy_metadata   = .false.,
   new_copy_metadata    = '',
   edit_qc_metadata     = .false.,
   new_qc_metadata      = '',
   edit_copies          = .false.,
   new_copy_index       = -1,
   new_copy_data        = -888888.
   edit_qc              = .false.,
   new_qc_index         = -1,
   new_qc_data          = 0.
   synonymous_copy_list = '',
   synonymous_qc_list   = '', 
/
</pre>
</div>

<br />
<br />


<div>
<TABLE border=0 cellpadding=10 width=100% summary='namelist description'>
<THEAD align=left>
<TR><TH> Item </TH>
    <TH> Type </TH>
    <TH> Description </TH> </TR>
</THEAD>

<TBODY valign=top>

<TR><TD>num_input_files</TD>
    <TD>integer</TD>
    <TD>The number of observation sequence files to process.
Maximum of 500.  If 0 the length is set by the number of input files
given.  If non-zero must match the given input file list length.
</TD></TR>

<TR><TD>filename_seq</TD>
    <TD>character(len=129), dimension(500)</TD>
    <TD>The array of names of the observation sequence files to process.
With the F90 namelist mechanism it is only necessary to specify the names
you are going to use, not all.
</TD></TR>

<TR><TD>filename_seq_list</TD>
    <TD>character(len=129)</TD>
    <TD>The name of a text file which contains, one per line,
the names of the observation sequence files to process.  You can only specify
one of filename_seq OR filename_seq_list, not both.
</TD></TR>

<TR><TD>filename_out</TD>
    <TD>character(len=129)</TD>
    <TD>The name of the resulting output observation sequence file.
</TD></TR>

<TR><TD>print_only</TD>
    <TD>logical</TD>
    <TD>If .TRUE., do not create an output file, but print a summary of the
number and types of each observation in each input file, and then the number
of observations and types which would have been created in an output file.
If other namelist selections are specified (e.g. start and end times, select
by observation type, qc value, etc) the summary message will include the
results of that processing.
</TD></TR>

<TR><TD>first_obs_days</TD>
    <TD>integer</TD>
    <TD>If non-negative, restrict the timestamps of the observations
copied to the output file to be equal to or after this day number (specified
in the Gregorian calendar; day number since 1600).
</TD></TR>

<TR><TD>first_obs_seconds</TD>
    <TD>integer</TD>
    <TD>If non-negative, restrict the timestamps of the observations
copied to the output file to be equal to or after this time.
</TD></TR>

<TR><TD>last_obs_days</TD>
    <TD>integer</TD>
    <TD>If non-negative, restrict the timestamps of the observations
copied to the output file to be equal to or before this date
(specified in the Gregorian calendar; day number since 1600).
</TD></TR>

<TR><TD>last_obs_seconds</TD>
    <TD>integer</TD>
    <TD>If non-negative, restrict the timestamps of the observations
copied to the output file to be equal to or before this time.
</TD></TR>

<TR><TD>obs_types</TD>
    <TD>character(len=32), dimension(500)</TD>
    <TD>The array of observation type names to process.  If any names
specified, then based on the setting of <em class=code>keep_types</em>,
these observation types will either be the only types kept in the
output file, or they will be removed and all other types will be copied
to the output file.
</TD></TR>

<TR><TD>keep_types</TD>
    <TD>logical</TD>
    <TD>Ignored unless one or more observation types are specified in the
<em class=code>obs_types</em> namelist.  If .TRUE., only the specified
observation types will be copied to the output file; if .FALSE., all
types except the listed ones will be copied to the output file.
</TD></TR>

<TR><TD>min_lat</TD>
    <TD>real(r8)</TD>
    <TD>If specified, the minimum latitude, in degrees, of observations
to be copied to the output file.  This assumes compiling with the 3d-sphere
locations module.
</TD></TR>

<TR><TD>max_lat</TD>
    <TD>real(r8)</TD>
    <TD>If specified, the maximum latitude, in degrees, of observations
to be copied to the output file.  This assumes compiling with the 3d-sphere
locations module.
</TD></TR>

<TR><TD>min_lon</TD>
    <TD>real(r8)</TD>
    <TD>If specified, the minimum longitude, in degrees, of observations
to be copied to the output file.  This assumes compiling with the 3d-sphere
locations module.  If min_lon is larger than max_lon, wrap across 360 to 0 is
assumed.
</TD></TR>

<TR><TD>max_lon</TD>
    <TD>real(r8)</TD>
    <TD>If specified, the maximum longitude, in degrees, of observations to be
copied to the output file.  This assumes compiling with the 3d-sphere locations 
module.  If min_lon is larger than max_lon, wrap across 360 to 0 is assumed.
</TD></TR>

<TR><TD>min_box</TD>
    <TD>real(r8)(:)</TD>
    <TD>If the locations are 1D, set a min value here instead of using
the lat/lon box values.
</TD></TR>

<TR><TD>max_box</TD>
    <TD>real(r8)(:)</TD>
    <TD>If the locations are 1D, set a max value here instead of using
the lat/lon box values.
</TD></TR>

<TR><TD>qc_metadata</TD>
    <TD>character</TD>
    <TD>If specified, the metadata string describing one of the quality
control (QC) fields in the input observation sequence files.
</TD></TR>

<TR><TD>min_qc</TD>
    <TD>real</TD>
    <TD>If specified, the minimum qc value in the QC field matching the
qc_metadata name that will be copied to the output file. 
</TD></TR>

<TR><TD>max_qc</TD>
    <TD>real</TD>
    <TD>If specified, the maximum qc value in the QC field matching the
qc_metadata name that will be copied to the output file. 
</TD></TR>

<TR><TD>copy_type</TD>
    <TD>character(len=32)</TD>
    <TD>If specified, the string name of an observation type to be copied
to the output file only if the min and max values specified are in range.
All other observation types are discarded if this option is specified.
</TD></TR>

<TR><TD>copy_metadata</TD>
    <TD>character</TD>
    <TD>If specified, the metadata string describing one of the data
copy fields in the input observation sequence files.
</TD></TR>

<TR><TD>min_copy</TD>
    <TD>real</TD>
    <TD>If specified, the minimum value in the data copy field matching the
copy_metadata name that will be copied to the output file. 
</TD></TR>

<TR><TD>max_copy</TD>
    <TD>real</TD>
    <TD>If specified, the maximum value in the data copy field matching the
copy_metadata name that will be copied to the output file. 
</TD></TR>

<TR><TD>gregorian_cal</TD>
    <TD>logical</TD>
    <TD>If .true. the dates of the first and last observations in each file
will be printed in both (day/seconds) format and in gregorian calendar
year/month/day hour:min:sec format.  Set this to .false. if the observations
were not created with gregorian calendar times.
</TD></TR>

<TR><TD>edit_copy_metadata</TD>
    <TD>logical</TD>
    <TD>If true, replace the output file metadata strings with the list
specified in the new_copy_metadata list.
</TD></TR>

<TR><TD>new_copy_metadata</TD>
    <TD>character(len=*)(:)</TD>
    <TD>List of new metadata strings.  Use with care, there is no error checking
to ensure you are doing a valid replacement.
</TD></TR>

<TR><TD>edit_copies</TD>
    <TD>logical</TD>
    <TD>If true, subset or rearrange the actual data copies in the output.
The new_copy_index list controls the output order of copies from the input files.
</TD></TR>

<TR><TD>new_copy_index</TD>
    <TD>integer(:)</TD>
    <TD>An array of integers, which control how copies in the input are
moved to the output sequence.  The values must be between 0 and the number of
copies in the input sequence.  They can be repeated to replicate an existing
copy; they can be specified in any order to reorder the entries; they can
include the value 0 to insert a new copy. -1 ends the list.  If -1 is
specified as the first value all copies will be deleted.
</TD></TR>

<TR><TD>new_copy_data</TD>
    <TD>real(:)</TD>
    <TD>An array of reals. The length should correspond to the number of 0s
in the new_copy_index list, and will be the data value for the new copies.
This value will be constant for all observations.
</TD></TR>

<TR><TD>edit_qc_metadata</TD>
    <TD>logical</TD>
    <TD>If true, replace the output file metadata strings with the list
specified in the new_qc_metadata list.
</TD></TR>

<TR><TD>new_qc_metadata</TD>
    <TD>character(len=*)(:)</TD>
    <TD>List of new metadata strings.  Use with care, there is no error checking
to ensure you are doing a valid replacement.
</TD></TR>

<TR><TD>edit_qcs</TD>
    <TD>logical</TD>
    <TD>If true, subset or rearrange the actual data QCs in the output.
The new_qc_index list controls the output order of QCs from the input files.
</TD></TR>

<TR><TD>new_qc_index</TD>
    <TD>integer(:)</TD>
    <TD>An array of integers, which control how QCs in the input are
moved to the output sequence.  The values must be between 0 and the number of
QCs in the input sequence.  They can be repeated to replicate an existing
QCs; they can be specified in any order to reorder the entries; they can
include the value 0 to insert a new qc. -1 ends the list.  If -1 is specified
as the first value, all QCs will be deleted.
</TD></TR>

<TR><TD>new_qc_data</TD>
    <TD>real(:)</TD>
    <TD>An array of reals. The length should correspond to the number of 0s
in the new_qc_index list, and will be the data value for the new QCs.  
This value will be constant for all observations.
</TD></TR>

<TR><TD>synonymous_copy_list</TD>
    <TD>character(len=*)(:)</TD>
    <TD>An array of strings which are to be considered synonyms in the copy
metadata strings for all the input obs seq files.  Any string in this list
will match any other string.  The first obs sequence file to copy
observations to the output file will set the actual values used, unless they
are explicitly overridden by edit_copy_metadata.

</TD></TR>

<TR><TD>synonymous_qc_list</TD>
    <TD>character(len=*)(:)</TD>
    <TD>An array of strings which are to be considered synonyms in the qc
metadata strings for all the input obs seq files.  Any string in this list
will match any other string.  The first obs sequence file to qc observations
to the output file will set the actual values used, unless they are
explicitly overridden by edit_qc_metadata.  
</TD></TR>


</TBODY> 
</TABLE>
</div>

<br />
<br />

<!--==================================================================-->

<A NAME="Examples"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>EXAMPLES</H2>

<P>
Here are details on how to set up common cases using this tool:
</P>
<ul>
<li><a href="#merge">Merge multiple files</a>
<li><a href="#timeclamp">Subset in Time</a>
<li><a href="#keepobs">Subset by Observation Type</a>
<li><a href="#byloc">Subset by Location</a>
<li><a href="#ascii">Binary to ASCII and back</a>
<li><a href="#editmeta">Merging files with incompatible Metadata</a>
<li><a href="#editdata">Altering the number of Copies or QC values</a>
<li><a href="#print">Printing only</a>
<li><a href="#keepval">Subset by Observation or QC Value</a>
</ul>

<A NAME="merge"></A>
<h3>Merge multiple files</h3>
<P>
Either specify a list of input files for <em class=code>filename_seq</em>, like:
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq       = 'obs_seq20071101',
                        'qscatL2B_2007_11_01a.out',
                        'obs_seq.gpsro_2007110106',
   filename_out       = 'obs_seq20071101.all',
   gregorian_cal      = .true.
/
</pre>
<P>
and all observations in each of the three input files will be merged
in time order and output in a single observation sequence file.
Or, at the command line, create a file containing one filename per line,
either with 'ls':
</P>
<pre>
&gt; ls obs_seq_in* &gt; tlist
</pre>
<P>
or with a text editor, or any other tool of your choice.  Then, 
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq_list = 'tlist',
   filename_out       = 'obs_seq20071101.all',
   gregorian_cal      = .true.
/
</pre>
<P>
will open 'tlist' and read the filenames, one per line, and merge them
together.  The output file will be named 'obs_seq20071101.all'.
</P>

<A NAME="timeclamp"></A>
<h3>Subset in Time</h3>
<P>
The observations copied to the output file can be restricted in
time by setting the namelist items for the first and last observation
timestamps (in days and seconds).
It is not an error for some of the input
files to have no observations in the requested time range, and 
multiple input files can have overlapping time ranges.
For example:
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq       = 'obs_seq20071101',
                        'qscatL2B_2007_11_01a.out',
                        'obs_seq.gpsro_2007110106',
   filename_out       = 'obs_seq20071101.06hrs',
   first_obs_days     = 148592,
   first_obs_seconds  =  10801,
   last_obs_days      = 148592,
   last_obs_seconds   =  32400,
   gregorian_cal      = .true.
/
</pre>
The time range is inclusive on both ends;
observations with times equal to the boundary times will 
be copied to the output.
To split a single input file up into proper subsets
(no replicated observations), the first time of the following
output sequence should be +1 second from the last time of the previous 
output sequence.   If the goal is to match an observation sequence file
with an assimilation window during the execution of the 
<em class="program">filter</em> program, the windows should be centered 
around the assimilation time starting at minus 1/2 the window time 
plus 1 second, and ending at exactly plus 1/2 the window time.

<A NAME="keepobs"></A>
<h3>Subset by Observation Type</h3>
<P>
You specify a list of observation types, by string name, and then
specify a logical value to say whether this is the list of observations
to keep, or if it's the list of observations to discard.  For example,
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq       = 'obs_seq20071101.06hrs',
   filename_out       = 'obs_seq20071101.wind',
   obs_types          = 'RADIOSONDE_U_WIND_COMPONENT',
                        'RADIOSONDE_V_WIND_COMPONENT',
   keep_types         = .true.,
   gregorian_cal      = .true.
/
</pre>
<P>
will create an output file which contains only the U and V wind
observations from the given input file.
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq       = 'obs_seq20071101.06hrs',
   filename_out       = 'obs_seq20071101.notemp',
   obs_types          = 'RADIOSONDE_TEMPERATURE',
   keep_types         = .false.,
   gregorian_cal      = .true.
/
</pre>
<P>
will strip out all the radiosonde temperature observations
and leave everything else.
</P>

<A NAME="byloc"></A>
<h3>Subset by Location</h3>
<P>
If the observations have locations specified in 3 dimensions,
as latitude, longitude, and a vertical coordinate, then it can 
be subset by specifying the corners of a lat, lon box.  There is
currently no vertical subsetting option.  For example:
</P>
<pre>
   min_lat            =    0.0,
   max_lat            =   20.0,
   min_lon            =  230.0,
   max_lon            =  260.0,
</pre>
<P>
will only output observations between 0 and 20 latitude
and 230 to 260 in longitude.  Latitude ranges are &minus;90 to 90,
longitude can either be specified from &minus;180 to +180, or 0 to 360.
</P>
<!-- i am using minus here because a regular dash was allowing a line
     break between it and the 180, depending on the page width. 
     i could not find another way to always keep them together.
-->
<P>
If the observations have 1 dimensional locations, between 0 and 1,
then a bounding box can be specified like:
</P>
<pre>
   min_box = 0.2,
   max_box = 0.4,
</pre>
<P>
will keep only those observations between 0.2 and 0.4.  In all
these tests, points on the boundaries are considered inside the box.
</P>

<A NAME="ascii"></A>
<h3>Binary to ASCII and back</h3>
<P>
To convert a (more compact) binary observation sequence file to 
a (human readable and portable) ASCII file, a single input and 
single output file can be specified with no selection criteria.
The output file format is specified by the 
<em class=code>write_binary_obs_sequence</em> item in
the <em class=code>&amp;obs_sequence_nml</em> namelist 
in the <em class=file>input.nml</em> file.
It is a Fortran logical; setting it to <em class=code>.TRUE.</em>
will write a binary file, setting it to <em class=code>.FALSE.</em>
will write an ASCII text file.  If you have a binary file, it must
be converted on the same kind of platform as it was created on before
being moved to another architecture.  At this point in time, there are
only 2 remaining incompatible platforms:  IBM systems based on PowerPC
chips, and everything else (which is Intel or AMD).
</P><P>
Any number of input files and selection options can be specified, as well,
but for a simple conversion, leave all other input namelist items unset.
</P>

<A NAME="editmeta"></A>
<h3>Merging files with incompatible Metadata</h3>
<P>
To merge files which have the same number of copies and qc but
different labels for what is exactly the same data, you can specify
a list of synonym strings that will pass the matching test.  For example:
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq       = 'qscatL2B_2007_11_01.out',
                        'obs_seq20071101',
                        'obs_seq.gpsro_2007110124',
   filename_out       = 'obs_seq20071101.all',
   gregorian_cal      = .true.
   synonymous_copy_list = 'NCEP BUFR observation', 'AIRS observation', 'observation',
   synonymous_qc_list   = 'NCEP QC index', 'AIRS QC', 'QC flag - wvc quality flag', 'QC',
/
</pre>
<P>
will allow any copy listed to match any other copy on that list, and 
same with the QC values.  If the output metadata strings are not 
specified (see below), then the actual metadata strings from the first 
file which is used will set the output metadata strings.
</P><P>
To rename or override, with care, existing metadata strings in a file,
set the appropriate edit strings to true, and set the same number
of copies and/or QC values as will be in the output file.  
Note that this will 
replace, without warning, whatever is originally listed as metadata.
You can really mangle things here, so use this with caution:
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq       = 'qscat_all_qc_305.out', 'qscat_all_qc_306.out',
   filename_out       = 'qscat_1_qc_2007_11.out',
   edit_copy_metadata = .true.,
   new_copy_metadata  = 'observation', 
   edit_qc_metadata   = .true.,
   new_qc_metadata    = 'QC', 'DART quality control',
   gregorian_cal      = .true.
/
</pre>
<P>
The log file will print out what input strings are being replaced;
check this carefully to be sure you are doing what you expect.
</P><P>
If you use both a synonym list and the edit list, the output file will
have the specified edit list strings for metadata.
</P>

<A NAME="editdata"></A>
<h3>Altering the number of Copies or QC values</h3>
<P>
To delete some of the copies or QC values in each observation, specify
the copy or QC index numbers which are to be passed through, and list 
them in the exact order they should appear in the output:
</P>
<pre>
   edit_copies = .true.,
   new_copy_index = 1, 2, 81, 82,

   edit_qcs = .true.,
   new_qc_index = 2, 
</pre>
<P>
This will create an output sequence file with only 4 copies; the original
first and second copies, and copies 81 and 82.  The original metadata will
be retained.  It will have only the second QC value from the original file.
</P><P>
If you are editing the copies or QCs and also specifying new metadata 
strings, use the number and order appropriate to the output file
regardless of how many copies or QC values there were in the original 
input files.
</P><P>
You can use these index lists to reorder copies or QC values by
specifying the same number of index values as currently exist
but list them in a different order.  Index values can be repeated
multiple times in a list.  This will duplicate both the metadata
string as well as the data values for the copy or QC.
</P><P>
To delete all copies or QCs specify -1 as the first (only) entry in 
the new index list.
</P>
<pre>
   edit_qcs = .true.,
   new_qc_index = -1, 
</pre>
<P>
To add copies or QCs, use 0 as the index value.
</P>
<pre>
   edit_copies = .true.,
   new_copy_index = 1, 2, 0, 81, 82, 0
   new_copy_data = 3.0, 8.0,

   edit_qcs = .true.,
   new_qc_index = 2, 1, 3, 0,
   new_qc_data = 1.0,
</pre>
<P>
This will insert 2 new copies in each observation and give
them values of 3.0 and 8.0 in all observations.  There is no 
way to insert a different value on a per-obs basis.  This example
will also reorder the 3 existing QC values and then add 1 new 
QC value of 1 in all observations.  The 'edit_copy_metadata' and
'edit_qc_metadata' flags with the 'new_copy_metadata' and 
'new_qc_metadata' lists can be used to set the metadata names 
of the new copies and QCs.
</P>
<pre>
   edit_copies = .true.,
   new_copy_index = 1, 0, 2, 0,
   new_copy_data = 3.0, 8.0,
   edit_copy_metadata = .true.,
   new_copy_metadata = 'observation', 'new copy 1',
                       'truth',       'new copy 2',

   edit_qcs = .true.,
   new_qc_index = 0, 2,
   new_qc_data = 0.0,
   edit_qc_metadata = .true.,
   new_qc_metadata = 'dummy QC', 'DART QC',
</pre>
<P>
To remove an existing QC value and add a QC value of 0
for all observations, run with:
</P>
<pre>
   edit_qcs = .true.,
   new_qc_index = 0,
   new_qc_data = 0.0,
   edit_qc_metadata = .true.,
   new_qc_metadata = 'dummy QC',
</pre>
<P>
to add a constant QC of 0 for all observations,
with a metadata label of 'dummy QC'.
</P>
<P>
It would be useful to allow copies or QCs from one file to be
combined, obs by obs, with those from another file.  However,
it isn't easy to figure out how to ensure the observations in
multiple files are in exactly the same order so data from
the same obs are being combined.  Also how to specify what
should be combined is a bit complicated.  So this functionality
is NOT available in this tool.
</P>

<A NAME="print"></A>
<h3>Printing only</h3>
<P>
Note that you can set all the other options and then set print true,
and it will do all the work and then just print out how many of each
obs type would have been created.  It is an easy way to preview what your
choices would do without waiting to write an output file.
It only prints the type breakdown for output file, but does print
a running total of how many obs are being kept from each input file.
For example:
</P>
<pre>
&amp;obs_sequence_tool_nml
   filename_seq       = 'obs_seq20071101',
   print_only         =  .true.,
/
</pre>

<A NAME="keepval"></A>
<h3>Subset by Observation or QC Value</h3>
<P>
You can specify a min, max data value and/or min, max qc value,
and only those within the range will be kept.  There is no exclude option.
For the data value, you must also specify an observation type since
different types have different units and valid ranges.  For example:
</P>
<pre>
# keep only observations with a DART QC of 0:
   qc_metadata        = 'Dart quality control',
   min_qc             = 0,
   max_qc             = 0,

# keep only radiosonde temp obs between 250 and 300 K:
   copy_metadata      = 'NCEP BUFR observation',
   copy_type          = 'RADIOSONDE_TEMPERATURE',
   min_copy           = 250.0,
   max_copy           = 300.0,
</pre>

<!--==================================================================-->

<A NAME="Discussion"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>DISCUSSION</H2>

<P>
DART observation sequence files are lists of individual observations,
each with a type, a time, one or more values (called copies), 
zero or more quality control flags,
a location, and an error estimate.  Regardless of the physical order
of the observations in the file, they are always processed in increasing
time order, using a simple linked list mechanism.  This tool reads in
one or more input observation sequence files, and creates a single
output observation sequence file with all observations sorted into
a single, monotonically increasing time ordered output file.
</P>

<P>
DART observation sequence files contain a header with the total
observation count and a table of contents of observation types.
The output file from this tool culls out unused observations, and
only includes observation types in the table of contents which
actually occur in the output file.  The table of contents 
<b>does not</b> need to be the same across multiple files to merge
them.  Each file has a self-contained numbering system for
observation types.  However, the <em class=code>obs_sequence_tool</em>
must be compiled with a list of observation types (defined in the
<em class=file>obs_def</em> files listed in the <em class=code>preprocess</em>
namelist) which includes all defined types across all input files.
See the <a href="#Building">building section</a> below for more
details on compiling the tool.
</P>

<P>
The tool can handle observation sequence files at any stage along the
processing pipeline: a template file with locations but no data, input
files for an assimilation which have observation values only, or output
files from an assimilation which then might include the prior and posterior
mean and standard deviation, and optionally the output from the forward
operator from each ensemble member. In all of these cases, the format
of each individual observation is the same.  It has zero or more 
<em>copies</em>, which is where the observation value and the means,
forward operators, etc are stored.
Each observation also has zero
or more quality control values, <em>qc</em>, which can be associated
with the incoming data quality, or can be added by the DART software
to indicate how the assimilation processed this observation.  Each of 
the copies and qc entries has an single associated character label 
at the start of the observation sequence file
which describes what each entry is, called the <em>metadata</em>.
</P>

<P>
For multiple observation sequence files to be merged
they must have the same number of <em>copies</em> and <em>qc</em> values,
and all associated <em>metadata</em> must be identical.
To merge multiple files where the numbers do not match exactly, the
tool can be used on the individual files to rename, subset, and
reorder the <em>copies</em> and/or <em>qc</em> first, and then the
resulting files are mergeable.  
To merge multiple files where the metadata strings do not match,
but the data copy or qc values are indeed the same things, there are
options to rename the metadata strings.  <b>This option should be
used with care.  If the copies or qc values in different files are not
really the same, the tool will go ahead and merge them but the resulting
file will be very wrong.</b>
</P>

<P>
The latest version of the tool offers an additional option for specifying
a list of input files.  The user creates an ASCII file by any appropriate
method, with one filename per line.  They specify this file with the
<em class=code>filename_seq_list</em> namelist item, and the tool opens
each input file in turn and processes the list.  In previous versions of
the tool the user had to specify a count of the number of input files.
In the current version, if the number of input files,
<em class=code>num_input_files</em>, is unspecified or specified as 0,
the number will be computed automatically.  If a count is specified,
it must match either the explicit list in <em class=code>filename_seq</em>,
or the file count from the contents of <em class=code>filename_seq_list</em>.
</P>

<P>
Time is stored inside of DART as a day number and number of seconds,
which is the same no matter which calendar is being used.  But many
real-world observations use the Gregorian calendar for converting
between number of days and an actual date.  If the 
<em class=code>gregorian_cal</em> namelist item is set to
<em class=code>.TRUE.</em> then any times will be printed out
to the log file will be both in day/seconds and calendar date.  
If the observation times are not using the Gregorian calendar, then set
this value to <em class=code>.FALSE.</em> and only days/seconds will
be printed.
</P>

<P>
The most common use of this tool is to process a set of input files
into a single output file, or to take one input file and extract a subset
of observations into a smaller file.  The <a href="#Examples">examples</a>
section below outlines several common scenerios.
</P>

<P>
The tool now also allows the number of copies to be changed, but only
to select subsets or reorder them.  It is not yet possible to merge copies
or QCs from observations in different files into a 
single observation with more copies.
</P>

<P>
Observations can also be selected by a given range of quality
control values or data values.
</P>

<P>
Observations can be restricted to a given bounding box, either in
latitude and longitude (in the horizontal only), or if the observations
have 1D locations, then a single value for min_box and max_box can be 
specified to restrict the observations to a subset of the space.
</P>

<!--==================================================================-->

<A NAME="FAQ"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>FAQ</H2>

<h3>Can I merge files where the observation types are different?</h3>

<P>Yes.  The numbering in the table of contents at the top of each file 
is only local to that file.  All processing of types is done with the
string name, not the numbers.  Neither the set of obs types, nor the
observation numbers need to match across files.
</P>

<h3>I get an error about unknown observation types.</h3>
<P>
Look at the <em class=code>&amp;preprocess_nml</em> namelist in the
input.nml file in the directory where your tool was built.  It must
have all the observation types you need to handle listed in the
<em class=code>input_files</em> item.
</P>

<h3>Can I list more files than necessary in my input file list?</h3>
<P>
Sure.  It will take slightly longer to run, in that the tool must
open the file and check the times and observation types.  But it is
not an error to list files where no observations will be copied to the
output file.  It is a common task to list a set of observation files
and then set the first and last observation times, run the tool to
select a shorter time period, then change the first and last times
and run again with the same list of files.
</P>


<!--==================================================================-->

<A NAME="Building"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>BUILDING</H2>

<P>
Most <tt>$DART/models/*/work</tt> directories will build the tool along with
other executable programs.  It is also possible to build the
tool in the <tt>$DART/observations/utilities</tt> directory.
The <tt>preprocess</tt> program must be built and run first, to define
what set of observation types will be supported.  See the 
<a href="../preprocess/preprocess.html">preprocess documentation</a>
for more details on how to define the list and run it.
The combined list of all observation types which will be encountered
over all input files must be in the preprocess input list.
The other important choice when building the tool is to include a
compatible locations module.  For the low-order models,
the <tt>oned</tt> module should be used; for real-world observations,
the <tt>threed_sphere</tt> module should be used.
</P>

<!--==================================================================-->

<A NAME="OtherModulesUsed"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>MODULES USED</H2>
<PRE>
types_mod
utilities_mod
time_manager_mod
obs_def_mod
obs_sequence_mod
</PRE>

<!--==================================================================-->
<!-- Describe the Files Used by this module.                          -->
<!--==================================================================-->

<A NAME="FilesUsed"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>FILES</H2>
<UL><LI><em class="file">input.nml</em></LI>
    <LI>The input files specified in the <em class="code">filename_seq</em>
        namelist variable.</LI>
    <LI>The output file specified in the <em class="code">filename_out</em>
        namelist variable.</LI>
</UL>

<!--==================================================================-->
<!-- Cite references, if need be.                                     -->
<!--==================================================================-->

<A NAME="References"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>REFERENCES</H2>
<ul>
<li> none </li>
</ul>

<!--==================================================================-->
<!-- Describe all the error conditions and codes.                     -->
<!--==================================================================-->

<A NAME="Errors"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>ERROR CODES and CONDITIONS</H2>
<div class=errors>
<TABLE border=1 cellspacing=1 cellpadding=10 width=100%>
<TR><TH>Routine</TH><TH>Message</TH><TH>Comment</TH></TR>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>num_input_files &gt; max_num_input_files. 
		    change max_num_input_files in source file</TD>
    <!-- comment --><TD VALIGN=top>The default is 500 files.</TD>
</TR>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>num_input_files and filename_seq mismatch</TD>
    <!-- comment --><TD VALIGN=top>The number of filenames does not match
                        the filename count.</TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>use either lat/lon box or min/max box but not both
                    </TD>
    <!-- comment --><TD VALIGN=top>When selecting a region you can specify a box by
                     latitude/longitude namelist limits, or you can use the 
                     min/max box namelist lists but not both.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top> can only use lat/lon box with 2d/3d sphere locations
                    </TD>
    <!-- comment --><TD VALIGN=top>
                     The lat/lon limits work only for the 2D and 3D sphere locations.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>min_lat must be less than max_lat 
                    </TD>
    <!-- comment --><TD VALIGN=top>adjust region limits so min is less than max
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>min_lat cannot be less than -90.0 degrees<br>
                                   max_lat cannot be greater than 90.0 degrees<br>
                                   min_lon cannot be greater than 360.0 degrees<br>
                                   max_lon cannot be greater than 360.0 degrees<br>
                    </TD>
    <!-- comment --><TD VALIGN=top>fix latitude limits to be within -90 to 90, 
                     longitude limits to be 0 to 360.  if longitude is negative,
                     360 will be added so values of -180 to 180 are ok.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top> min_lon cannot exactly equal max_lon<br>
                                    min_lat cannot exactly equal max_lat
                    </TD>
    <!-- comment --><TD VALIGN=top> the region select box must have a positive volume
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top> must specify the metadata name of a QC field
                    </TD>
    <!-- comment --><TD VALIGN=top> if selecting observations by QC value, you must 
                      specify the metadata string for which QC field to use.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top> must specify the metadata name of a copy field
                    </TD>
    <!-- comment --><TD VALIGN=top> if selecting observations by value, you must
                      specify the metadata string for which copy field to use.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top> first time cannot be later than last time
                    </TD>
    <!-- comment --><TD VALIGN=top> if selecting a time range, the interval must 
                      be legal
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top> new_copy_index values must be between 0 and N
                    </TD>
    <!-- comment --><TD VALIGN=top> if reordering or selecting only certain copies
                      the list must only include valid indices from the input sequence 
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top> new_qc_index values must be between 0 and N
                    </TD>
    <!-- comment --><TD VALIGN=top> if reordering or selecting only certain QCs
                      the list must only include valid indices from the input sequence 
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>All input files are empty or all obs excluded by time/type/location
                    </TD>
    <!-- comment --><TD VALIGN=top> The selection criteria has excluded all the 
                    possible observations, or none of the input observation sequence 
                    files contain observations.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>Internal error trying to process file
                    </TD>
    <!-- comment --><TD VALIGN=top> Shouldn't happen.  Contact the DART development
                     team with details of how this occurred.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>observations must be in increasing time order
                    </TD>
    <!-- comment --><TD VALIGN=top> one or more of the input observation sequence files
                     has out-of-time-order observations.  This should not happen if
                     the input file was created with DART subroutines.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>cannot specify both filename_seq and filename_seq_list
                    </TD>
    <!-- comment --><TD VALIGN=top> in the input namelist, you can either give a file
                     or a list of files for the 'filename_seq' item, or you can give
                     the name of a file that contains the names in 'filename_seq_list',
                     but you cannot specify both.  set one of these to ''.
                    </TD>

<TR><!-- routine --><TD VALIGN=top>obs_sequence_tool</TD>
    <!-- message --><TD VALIGN=top>contains no filenames
                    </TD>
    <!-- comment --><TD VALIGN=top> the 'filename_seq_list' file contains no filenames
                     to be used as input observation sequence files
                    </TD>

</TR>
</TABLE>
</div>

<H2>KNOWN BUGS</H2>
<P>
none
</P>

<!--==================================================================-->
<!-- Describe Future Plans.                                           -->
<!--==================================================================-->

<A NAME="FuturePlans"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>FUTURE PLANS</H2>
<P>
Long laundry list of things this tool could do, including:
</P>
<UL>
<LI>Combine copies or qc fields from multiple files into a single 
    observation</LI>
<LI>Select based on vertical location value.  (Complicated by the
    options of specifying vertical in meters, pressure, or model levels.)</LI>
<LI>Sort obs with identical timestamps by a specified type list, so
    one kind of ob gets assimilated before another.</LI>
<LI>Sort obs with idential timestamps so any at the same location 
    are contiguous in file
    (so the internal caching of previous locations will be more efficient).</LI>
<LI>Remove duplicates (difficult to accurately compare floating
    point values, but identical obs should be possible to recognize,
    or some epsilon could be specified.)</LI>
<LI>A way to split a single input file into multiple output files,
    based on a time interval. Now with the <em>schedule</em> type,
    specifying the intervals is easy; need a way to generate the
    output filenames with a pattern.</LI>
<LI>Eventually move to NetCDF for observation sequence files.  The
    complication is that it's possible for observations to contain
    additional information on a per-type basis, which means the
    arrays of data are no longer the same size.  Perhaps features of
    NetCDF 4 can be used in this case. </LI>
</UL>

<!--==================================================================-->
<!-- Legalese & Metadata                                              -->
<!--==================================================================-->

<A NAME="Legalese"></A>
<div class="top">[<a href="#">top</a>]</div><hr />
<H2>Terms of Use</H2>

<P>
DART software - Copyright 2004 - 2013 UCAR.<br>
This open source software is provided by UCAR, "as is",<br>
without charge, subject to all terms of use at<br>
<a href="http://www.image.ucar.edu/DAReS/DART/DART_download">
http://www.image.ucar.edu/DAReS/DART/DART_download</a>
</P>

<TABLE border=0 cellpadding=0 width=100% summary="">
<TR><TD valign=top>Contact:       </TD><TD> DART core group   </TD></TR>
<TR><TD valign=top>Revision:      </TD><TD> $Revision$ </TD></TR>
<TR><TD valign=top>Source:        </TD><TD> $URL$ </TD></TR>
<TR><TD valign=top>Change Date:   </TD><TD> $Date$ </TD></TR>
<TR><TD valign=top>Change&nbsp;history:&nbsp;</TD><TD> try "svn&nbsp;log" or "svn&nbsp;diff" </TD></TR>
</TABLE>

<!--==================================================================-->

</BODY>
</HTML>
