#!/bin/csh
#
# DART software - Copyright UCAR. This open source software is provided
# provided by UCAR, "as is", without charge, subject to all terms of use at
# http://www.image.ucar.edu/DAReS/DART/DART_download
#
# ------------------------------------------------------------------------------
# Purpose: perform a multi-instance advance of CLM and then assimilate.
#          The assumptions here are that there is an ensemble of CLM states
#          available (as well as the CESM-required ROF states).
#
# The example configured here is for daily assimilation - at 00Z.
# Some variables for the DART state come from the CLM restart file,
# some from the .h0. file that has 30-minute values in it, some from
# a .h2. file that is still in the vector-based format.
#
# An example of assimilating monthly can be found in CLM5_monthly_assim.csh
# ------------------------------------------------------------------------------

# All the user-specified variables and settings are read from a DART
# parameter file. This includes the case name, ensemble size, the location
# of the CESM code, etc. There are still some variables that are logically
# defined in this script, as well as some specifics about the CLM namelists.

source DART_params.csh

# Prevent accidental removal of an experiment.
# If you want to replace the experiment, you have to manually
# remove the directories. 

if ( -e ${caseroot} ) then
   echo "WARNING : ${caseroot} already exists."
   echo "EXISTING: ${caseroot}"
   echo "EXISTING: ${exeroot}"
   echo "EXISTING: ${rundir}"
   echo "These directories need to be removed or the case must be renamed"
   echo "WARNING : Stopping."
   exit
endif

# ==============================================================================
# job settings:
#
# run_queue, run_time, st_archive_queue, st_archive_time may be changed at any time

setenv run_queue regular
setenv run_time 00:30:00

# the short-term archiver is turned off (initially?) to let you explore the
# run directory

setenv short_term_archiver off
setenv st_archive_queue share
setenv st_archive_time 06:00:00

# ==============================================================================
# Create the case - this creates the CASEROOT directory.
#
# FATAL idea to make caseroot the same dir as where this setup script is
# since the build process removes all files in the caseroot dir before
# populating it.  try to prevent shooting yourself in the foot.

if ( ${caseroot} == `pwd` ) then
   echo "ERROR: the setup script should not be located in the caseroot"
   echo "directory, because all files in the caseroot dir will be removed"
   echo "before creating the new case.  move the script to a safer place."
   exit 1
endif

echo "removing old files from ${caseroot}"
echo "removing old files from ${exeroot}"
echo "removing old files from ${rundir}"

${REMOVE} ${caseroot}
${REMOVE} ${exeroot}
${REMOVE} ${rundir}
${cesmroot}/cime/scripts/create_newcase  --res  ${resolution} \
                                         --mach ${machine} \
                                         --compset ${compset} \
                                         --case ${caseroot} \
                                         --project ${project} \
                                         --run-unsupported \
                                         --ninst ${num_instances} \
                                         --multi-driver || exit 2

# ==============================================================================
# Preserve a copy of this script and the parameter file as it was run.
# Copy the DART setup script (CESM_DART_config) to CASEROOT.

set ThisFileName = $0:t
${COPY} $ThisFileName       ${caseroot}/${ThisFileName}.original
${COPY} DART_params.csh     ${caseroot}
${COPY} CESM_DART_config    ${caseroot}

# ==============================================================================
cd ${caseroot}
# ==============================================================================

# Save a copy for debug purposes
foreach FILE ( *xml )
   if ( ! -e          ${FILE}.original ) then
      ${COPY} ${FILE} ${FILE}.original
   endif
end

# Get a bunch of environment variables.
# If any of these are changed by xmlchange calls in this program,
# then they must be explicty changed with setenv calls too.

setenv COMPSET               `./xmlquery COMPSET               --value` || exit 3
setenv COMP_ATM              `./xmlquery COMP_ATM              --value` || exit 3
setenv COMP_OCN              `./xmlquery COMP_OCN              --value` || exit 3
setenv CASEROOT              `./xmlquery CASEROOT              --value` || exit 3

# Make sure the case is configured with a stub ocean and a data atmosphere.

if ( (${COMP_OCN} != socn) || (${COMP_ATM} != datm) ) then
   echo " "
   echo "ERROR: This script is not appropriate for active ocean or atmospheric compsets."
   echo " "
   exit 3
endif

./xmlchange STOP_OPTION=${stop_option}
./xmlchange STOP_N=${stop_n}
./xmlchange RESUBMIT=${resubmit}

./xmlchange CALENDAR=GREGORIAN
./xmlchange CIME_OUTPUT_ROOT=${cime_output_root}
./xmlchange EXEROOT=${exeroot}
./xmlchange RUNDIR=${rundir}

# This comes from http://esmci.github.io/cime/data_models/data-atm.html
# "Note If DATM_MODE is set to CPLHIST, it is normally assumed that the model
# domain will be identical to all of the stream domains. To ensure this, the
# xml variables ATM_DOMAIN_PATH and ATM_DOMAIN_FILE are ignored and a valid
# setting must be given for DATM_CPLHIST_DOMAIN_FILE. If DATM_CPLHIST_DOMAIN_FILE
# is set to null, then the datm component domain information is read in from
# the first coupler history file in the target stream and it is assumed that the
# first coupler stream file that is pointed to contains the domain information
# for that stream. This is the default that should be used for this mode."

./xmlchange DATM_MODE=CPLHIST
./xmlchange DATM_CPLHIST_DOMAIN_FILE=null
./xmlchange DATM_CPLHIST_YR_ALIGN=${stream_year_align}
./xmlchange DATM_CPLHIST_YR_START=${stream_year_first}
./xmlchange DATM_CPLHIST_YR_END=${stream_year_last}

# --- In a hybrid run the model is initialized as a startup, BUT uses
# initialization datasets FROM A PREVIOUS case.  This
# is somewhat analogous to a branch run with relaxed restart
# constraints.  A hybrid run allows users to bring together combinations
# of initial/restart files from a previous case (specified by
# RUN_REFCASE) at a given model output date (specified by
# RUN_REFDATE). Unlike a branch run, the starting date of a hybrid run
# (specified by RUN_STARTDATE) can be modified relative to the reference
# case. In a hybrid run, the model does not continue in a bit-for-bit
# fashion with respect to the reference case. The resulting climate,
# however, should be continuous provided that no model source code or
# namelists are changed in the hybrid run.  In a hybrid initialization,
# the ocean model does not start until the second ocean coupling
# (normally the second day), and the coupler does a cold start without
# a restart file.</desc>

./xmlchange RUN_TYPE=hybrid
./xmlchange RUN_REFCASE=${refcase}
./xmlchange RUN_REFDATE=${refdate}
./xmlchange RUN_REFTOD=${reftod}
./xmlchange GET_REFCASE=FALSE

./xmlchange RUN_STARTDATE=${startdate}
./xmlchange START_TOD=${start_tod}

# pnetcdf is default
./xmlchange PIO_TYPENAME=pnetcdf

# Task layout:
# Set the nodes_per_instance below to match your case.
# By computing task counts like we do below, we guarantee each instance uses
# a whole number of nodes which is the recommended configuration.
# CIME interprets a negative task count as representing the number of nodes.
# On Cheyenne (at least) using multiple threads is not recommended.

@ nthreads = ${number_of_threads}

@ atm_tasks = -1 * ${nodes_per_instance}
@ cpl_tasks = -1 * ${nodes_per_instance}
@ ocn_tasks = -1 * ${nodes_per_instance}
@ wav_tasks = -1 * ${nodes_per_instance}
@ glc_tasks = -1 * ${nodes_per_instance}
@ ice_tasks = -1 * ${nodes_per_instance}
@ rof_tasks = -1 * ${nodes_per_instance}
@ lnd_tasks = -1 * ${nodes_per_instance}
@ esp_tasks = -1 * ${nodes_per_instance}

./xmlchange ROOTPE_ATM=0,NTHRDS_ATM=$nthreads,NTASKS_ATM=$atm_tasks
./xmlchange ROOTPE_CPL=0,NTHRDS_CPL=$nthreads,NTASKS_CPL=$cpl_tasks
./xmlchange ROOTPE_OCN=0,NTHRDS_OCN=$nthreads,NTASKS_OCN=$ocn_tasks
./xmlchange ROOTPE_WAV=0,NTHRDS_WAV=$nthreads,NTASKS_WAV=$wav_tasks
./xmlchange ROOTPE_GLC=0,NTHRDS_GLC=$nthreads,NTASKS_GLC=$glc_tasks
./xmlchange ROOTPE_ICE=0,NTHRDS_ICE=$nthreads,NTASKS_ICE=$ice_tasks
./xmlchange ROOTPE_ROF=0,NTHRDS_ROF=$nthreads,NTASKS_ROF=$rof_tasks
./xmlchange ROOTPE_LND=0,NTHRDS_LND=$nthreads,NTASKS_LND=$lnd_tasks
./xmlchange ROOTPE_ESP=0,NTHRDS_ESP=$nthreads,NTASKS_ESP=$esp_tasks

./xmlchange --subgroup case.run --id JOB_QUEUE          --val ${run_queue}
./xmlchange --subgroup case.run --id JOB_WALLCLOCK_TIME --val ${run_time}

echo "setting up the case ... "

./case.setup || exit 4

echo "case setup finished."

# ==============================================================================
# These are archiving options that may be used.

if (${short_term_archiver} == 'off') then
   ./xmlchange DOUT_S=FALSE
else
   ./xmlchange DOUT_S=TRUE
   ./xmlchange --subgroup case.st_archive --id JOB_QUEUE          --val ${st_archive_queue}
   ./xmlchange --subgroup case.st_archive --id JOB_WALLCLOCK_TIME --val ${st_archive_time}
endif

# DEBUG = TRUE implies turning on run and compile time debugging.
# INFO_DBUG level of debug output, 0=minimum, 1=normal, 2=more, 3=too much.

./xmlchange DEBUG=FALSE
./xmlchange INFO_DBUG=0

# ==============================================================================
# Use the stream template that has all CAM reanalysis years available.

   set STREAMFILE_SOLAR        = datm.streams.txt.CPLHISTForcing.Solar_complete
   set STREAMFILE_STATE1HR     = datm.streams.txt.CPLHISTForcing.State1hr_complete
   set STREAMFILE_STATE3HR     = datm.streams.txt.CPLHISTForcing.State3hr_complete
   set STREAMFILE_NONSOLARFLUX = datm.streams.txt.CPLHISTForcing.nonSolarFlux_complete

# ==============================================================================
# Modify namelist templates for each instance.
#
# In a hybrid run with CONTINUE_RUN = FALSE (i.e. just starting up):
# CLM builds its own 'finidat' value from the REFCASE variables.
#
# All of these must later on be staged with the expected filenames.

@ inst = 1
while ( $inst <= $num_instances )

   set inst_string = `printf %04d $inst`

   # ===========================================================================
   set fname = "user_nl_datm_${inst_string}"
   # ===========================================================================
   # DATM namelist

   set FILE1 = datm.streams.txt.CPLHISTForcing.Solar_${inst_string}
   set FILE2 = datm.streams.txt.CPLHISTForcing.State1hr_${inst_string}
   set FILE3 = datm.streams.txt.CPLHISTForcing.State3hr_${inst_string}
   set FILE4 = datm.streams.txt.CPLHISTForcing.nonSolarFlux_${inst_string}
   set DOMAINFILE = '/glade/p/cesmdata/cseg/inputdata/share/domains/domain.lnd.fv0.9x1.25_gx1v7.151020.nc'

   echo "domainfile = '${DOMAINFILE}'" >> ${fname}
   echo "streams = '$FILE1 $stream_year_align $stream_year_first $stream_year_last',"  >> ${fname}
   echo "          '$FILE2 $stream_year_align $stream_year_first $stream_year_last',"  >> ${fname}
   echo "          '$FILE3 $stream_year_align $stream_year_first $stream_year_last',"  >> ${fname}
   echo "          '$FILE4 $stream_year_align $stream_year_first $stream_year_last',"  >> ${fname}
   echo "          'datm.streams.txt.presaero.clim_2000_${inst_string} 2000 2000 2000'" >> ${fname}
   echo "vectors  = 'u:v' "     >> ${fname}
   echo "mapmask  = 'nomask', " >> ${fname}
   echo "           'nomask', " >> ${fname}
   echo "           'nomask', " >> ${fname}
   echo "           'nomask'  " >> ${fname}
   echo "tintalgo = 'coszen', " >> ${fname}
   echo "           'linear', " >> ${fname}
   echo "           'linear', " >> ${fname}
   echo "           'nearest' " >> ${fname}

   # Create stream files for each ensemble member
   set SOURCEDIR = ${dartroot}/models/clm/shell_scripts/cesm2_2
   ${COPY} ${SOURCEDIR}/${STREAMFILE_SOLAR}         user_${FILE1} || exit 5
   ${COPY} ${SOURCEDIR}/${STREAMFILE_STATE1HR}      user_${FILE2} || exit 5
   ${COPY} ${SOURCEDIR}/${STREAMFILE_STATE3HR}      user_${FILE3} || exit 5
   ${COPY} ${SOURCEDIR}/${STREAMFILE_NONSOLARFLUX}  user_${FILE4} || exit 5

   foreach FNAME ( user_datm.streams.txt*_${inst_string} )
      echo "modifying $FNAME"
      sed s/NINST/${inst_string}/g $FNAME >! temp
      sed s/RUNYEAR/${stream_year_first}/g temp >! $FNAME
   end
   ${REMOVE} temp

   # ===========================================================================
   set fname = "user_nl_clm_${inst_string}"
   # ===========================================================================

   # We are explicitly constructing the 'finidat' to match what is getting
   # staged by the 'stage_cesm_files' script. This file will almost surely
   # need to be intepolated to whatever resolution/land surface description
   # CLM is currently using. The interpolation only happens when CONTINUE_RUN
   # is FALSE, i.e. only for the first cycle.
   #
   # This is the opportunity to output additional items at your own discretion.
   # may want to track the evolution of certain variables at different timescales.
   #
   # hist_nhtfrq: Per tape series history write frequency.
   #              positive means in time steps 0=monthly negative means hours
   #              i.e. 5 means every 24 time-steps and -24 means every day
   #              Default: 0,-24,-24,-24,-24,-24
   # hist_mfilt:  Per tape series maximum number of time samples.
   # EXAMPLE with stop_option = 'nhours' and 'stop_n' is 24
   #  hist_nhtfrq          =    -24,     1,   -24
   #  hist_mfilt           =      1,    48,     1
   #  hist_avgflag_pertape =    'A',   'A',    'I'
   #  hist_dov2xy          = .true.,.true.,.false.
   #  means the .h0. will be daily averages in lat/lon space
   #  means the .h1. will have 48 'averages' (i.e. every 30 mins) in lat/lon space
   #  means the .h2. will have an instantaneous value in the same 'vector' format
   #                 as the restart file.

   # Here are some of the candidate variables. Generally do not want ALL possible
   # variables - the files are already huge, and we have an ensemble of them.
   # FSH            units="W/m^2"    long_name='sensible heat not including correction for ... 
   # FSDSVD         units='W/m^2'    long_name='direct vis incident solar radiation'
   # FSDSVI         units='W/m^2'    long_name='diffuse vis incident solar radiation'
   # FSDSVDLN       units='W/m^2'    long_name='direct vis incident solar radiation at local noon'
   # FSDSVILN       units='W/m^2'    long_name='diffuse vis incident solar radiation at local noon'
   # PARVEGLN       units='W/m^2'    long_name='absorbed par by vegetation at local noon'
   # EFLX_LH_TOT    units='W/m^2'    long_name='total latent heat flux [+ to atm]'
   # EFLX_LH_TOT_R  units='W/m^2'    long_name='Rural total evaporation'
   # TLAI           units='m^2/m^2'  long_name='total projected leaf area index'
   # NEP            units='gC/m^2/s' long_name='net ecosystem production, excludes ...
   # GPP            units='gC/m^2/s' long_name='gross primary production'



   echo "finidat = '"${refcase}.clm2_${inst_string}.r.${reftimestamp}.nc"'" >> ${fname}
   echo "use_init_interp = .true."                                          >> ${fname}
   echo "init_interp_fill_missing_with_natveg = .true."                     >> ${fname}
   echo "use_lch4 = .false."                                                >> ${fname}
   echo "hist_empty_htapes = .true."                                        >> ${fname}
   echo "hist_fincl1 = 'NEP','H2OSOI','SMINN_vr','LITR1N_vr','TSOI','EFLX_LH_TOT','TLAI','FSDSVDLN','FSDSVILN','PARVEGLN'"   >> ${fname}
   echo "hist_fincl2 = 'NEP','FSH','EFLX_LH_TOT_R','GPP'"                   >> ${fname}
   echo "hist_fincl3 = 'NEE','H2OSNO','TLAI','TWS','SOILC_vr','SOIL1N_vr','LEAFN','SMP'"  >> ${fname}
   echo "hist_nhtfrq = -$stop_n,1,-$stop_n"                                 >> ${fname}
   echo "hist_mfilt  = 1,$h1nsteps,1"                                       >> ${fname}
   echo "hist_avgflag_pertape = 'A','A','I'"                                >> ${fname}
   echo "hist_dov2xy = .true.,.true.,.false."                               >> ${fname}
   echo "hist_type1d_pertape = ' ',' ',' '"                                 >> ${fname}
  
 # ===========================================================================
   set fname = "user_nl_mosart_${inst_string}"
   # ===========================================================================

   # We are explicitly constructing the 'finidat_rtm' to match what is getting
   # staged by the 'stage_cesm_files' script.
   # If this file is not available or you do not want stage this file set finidat_rtm = ' '.

   echo "finidat_rtm = '"${refcase}.mosart_${inst_string}.r.${reftimestamp}.nc"'" >> ${fname}


   @ inst ++
end

./preview_namelists || exit 6

# ==============================================================================
# Stage the restarts now that the run directory exists
# ==============================================================================

echo "staging restarts"

set init_time = ${reftimestamp}

cat << EndOfText >! stage_cesm_files
#!/bin/csh -f
# This script can be used to help restart an experiment from any previous step.
# The appropriate files are copied to the RUN directory.
#
# Before running this script:
#  1) be sure CONTINUE_RUN is set correctly in the env_run.xml file in
#     your CASEROOT directory.
#     CONTINUE_RUN=FALSE => you are starting over at the initial time.
#     CONTINUE_RUN=TRUE  => you are starting from a previous step but not
#                           the very first one.
#  2) be sure 'restart_time' is set to the day and time that you want to
#     restart from if not the initial time.
#
#  3) be sure the prior inflation files are re-staged 
#     STAGE_INFLATION FALSE => no restage, default setting when case is first created
#     STAGE_INFLATION TRUE  => you are starting from a previous step or
#                              from the initial time            
#
#
#

set restart_time = $init_time
set STAGE_INFLATION = FALSE


# get the settings for this case from the CESM environment
cd ${caseroot}

setenv CONTINUE_RUN \`./xmlquery CONTINUE_RUN --value\`
setenv RUNDIR       \`./xmlquery RUNDIR       --value\`
setenv DOUT_S       \`./xmlquery DOUT_S       --value\`
setenv DOUT_S_ROOT  \`./xmlquery DOUT_S_ROOT  --value\`
setenv CASE         \`./xmlquery CASE         --value\`

cd \${RUNDIR}

echo 'Copying the required CESM files to the run directory to rerun'
echo 'a previous step.  CONTINUE_RUN from env_run.xml is' \${CONTINUE_RUN}
if ( \${CONTINUE_RUN} == TRUE ) then
  echo 'so files for some later step than the initial one will be restaged.'
  echo "Date to reset files to is: \${restart_time}"
else
  echo 'so files for the initial step of this experiment will be restaged.'
  echo "Date to reset files to is: ${init_time}"
endif
echo ''

if ( \${CONTINUE_RUN} == TRUE ) then

   #----------------------------------------------------------------------
   # This block copies over a set of restart files from any previous step of
   # the experiment that is NOT the initial step.
   # After running this script resubmit the job to rerun.
   #----------------------------------------------------------------------

   echo "Staging restart files for run date/time: " \${restart_time}

   #  The short term archiver is on, so the files we want should be in one
   #  of the short term archive 'rest' restart directories.  This assumes
   #  the long term archiver has NOT copied these files to the HPSS yet.

   if (  \${DOUT_S} == TRUE ) then

      # The restarts should be in the short term archive directory.

      set RESTARTDIR = \${DOUT_S_ROOT}/rest/\${restart_time}

      if ( ! -d \${RESTARTDIR} ) then

         echo "restart file directory not found: "
         echo " \${RESTARTDIR}"
         echo "If the long-term archiver is on, you may have to restore this directory first."
         echo "You can also check for either a .sta or a .sta2 hidden subdirectory in"
         echo "\${DOUT_S_ROOT}"
         echo "which may contain the 'rest' directory you need,"
         echo "and then modify RESTARTDIR in this script."
         exit 7

      endif

      ${COPY} \${RESTARTDIR}/* . || exit 7

   else

      # The short term archiver is off, which leaves all the restart files
      # in the run directory.  The rpointer files must still be updated to
      # point to the files with the right day/time.

      @ inst=1
      while (\$inst <= $num_instances)

         set inst_string = \`printf _%04d \$inst\`

         echo "\${CASE}.cpl\${inst_string}.r.\${restart_time}.nc"    >! rpointer.drv\${inst_string}
         echo "\${CASE}.clm2\${inst_string}.r.\${restart_time}.nc"   >! rpointer.lnd\${inst_string}
         echo "\${CASE}.datm\${inst_string}.r.\${restart_time}.nc"   >! rpointer.atm\${inst_string}
         echo "\${CASE}.datm\${inst_string}.rs1.\${restart_time}.nc" >> rpointer.atm\${inst_string}
         echo "\${CASE}.mosart\${inst_string}.r.\${restart_time}.nc" >! rpointer.rof\${inst_string}

         @ inst ++
      end

      # If the multi-driver is not being used,
      # there is only a single coupler restart file.
      echo "\${CASE}.cpl.r.\${restart_time}.nc" >! rpointer.drv

   endif

   echo "All files reset to rerun experiment step for time " \$restart_time

else     # CONTINUE_RUN == FALSE

   #----------------------------------------------------------------------
   # This block links the right files to rerun the initial (very first)
   # step of an experiment.  The names and locations are set during the
   # building of the case; to change them rebuild the case.
   # After running this script resubmit the job to rerun.
   #----------------------------------------------------------------------

   @ inst=1
   while (\$inst <= $num_instances)

      set inst_string = \`printf _%04d \$inst\`

      echo "Staging initial files for instance \$inst of $num_instances"

      if ( -e    ${stagedir}/${refcase}.clm2\${inst_string}.r.${init_time}.nc ) then
         ${LINK} ${stagedir}/${refcase}.clm2\${inst_string}.r.${init_time}.nc .
      else
         echo "ERROR: ${stagedir}/${refcase}.clm2\${inststring}.r.${init_time}.nc does not exist."
         echo "       Check your 'reftimestamp' setting, or maybe your 'stagedir' or 'refcase' or ..."
         exit 8
      endif

      if (-e     ${stagedir}/${refcase}.mosart\${inst_string}.r.${init_time}.nc ) then
         ${LINK} ${stagedir}/${refcase}.mosart\${inst_string}.r.${init_time}.nc .
      else
        echo "WARNING: ${stagedir}/${refcase}.mosart\${inst_string}.r.${init_time}.nc does not exist."
        echo "       Check your 'reftimestamp' setting, or maybe your 'stagedir' or 'refcase' or ..."
        echo "       If this is not a mistake, set finidat_rtm = ' ', within mosart namelist or input file"
      endif

      @ inst ++
   end

   echo "All files set to run the FIRST experiment step at time" $init_time

endif

   #----------------------------------------------------------------------
   # This block modifies the inflation rpointer files (priorinf_pointer_d{01-03}.txt)
   # such that the DART code uses the inflation files (clm_output_priorinf*.nc) from the 
   # previous time step (e.g. restart_time)
   # e.g. the following files:
   # clm_output_priorinf_mean_d01.2011-01-03-00000.nc
   # clm_output_priorinf_sd_d01.2011-01-03-00000.nc
   # would be used to apply inflation for time step: 2011-01-04
   #----------------------------------------------------------------------

if ( \${STAGE_INFLATION} == TRUE) then

# Confirm inflation is being used.

set  MYSTRING = \`grep inf_flavor input.nml\`
set  MYSTRING = \`echo \$MYSTRING | sed -e "s#[=,'\.]# #g"\`
set  PRIOR_INF = \$MYSTRING[2]
set  POSTE_INF = \$MYSTRING[3]

  if ( \$PRIOR_INF != 0 ) then

    if  ( \${CONTINUE_RUN} == FALSE) then
       # Generate cookie such that fill_inflation_restart 
       # generates inflation files

       date >! \${RUNDIR}/clm_inflation_cookie

    else  # CONTINUE_RUN=TRUE

         if ( ! -e priorinf_pointer_d01.txt ) then

         echo "ERROR: priorinf_pointer_d01.txt file not found"
         echo "At least 1 domain pointer file should exist if assimilation run is re-staged"
         echo "Prior inflation files will not be re-staged"
         exit 2

         endif

       @ domaincount = 0
       echo "     "
       echo "Re-setting priorinf pointer files for " \$restart_time
       echo "     "

     foreach POINTERFILE ( priorinf_pointer*.txt )

        @ domaincount ++

        set POINTERFILE = \`printf priorinf_pointer_d%02d.txt \$domaincount\`
        echo "Located inflation pointer file: " \$POINTERFILE
        set DOMAIN = \`printf _d%02d \$domaincount\`
        set FILE   = \`printf clm_output_priorinf_mean\${DOMAIN}.\${restart_time}.nc\`

         if ( ! -e \${FILE} ) then
         echo "ERROR: \${FILE} not found"
         echo "This file must exist to be inserted in \${POINTERFILE}"
         echo "Prior inflation file will not be re-staged"
         exit 3
         endif

        set SDFILE = \`echo \$FILE | sed -e "s#mean#sd#"\`
        echo "Inserting the prior inflation file into pointer: " \$FILE
        echo \$FILE   >! \$POINTERFILE
        echo \$SDFILE >> \$POINTERFILE

     end

     echo "The priorinf pointer files are reset to rerun experiment at: " \$restart_time
     echo "    "

    endif

  else   # \$PRIOR_INF==0

    echo "Warning: Prior inflation is turned off for this assimilation"
    echo "Inflation files will not be re-staged"
    echo "Check your input.nml inflation settings"

  endif

   if ( \$POSTE_INF != 0 ) then
      echo "ERROR: stage_cesm_files not configured to stage posterior inflation files."
      exit 4
   endif

endif

exit 0

EndOfText
chmod 0755 stage_cesm_files

./stage_cesm_files || exit 8

#===============================================================================
# This example has SourceMods that enable CLM to output solar induced fluorescence
# as an additional diagnostic variable ("FSIF") in the history file.
# There are also SourceMods that suppress the balance checks for the first
# restart timestep.

if ( ${use_SourceMods} == TRUE ) then

   if (    -d    ${SourceModDir} ) then
      ${COPY} -r ${SourceModDir}/* ${caseroot}/SourceMods/ || exit 7

      if ( -e    SourceMods/src.clm ) then
         cd      SourceMods/src.clm
         ${LINK} `find . -name "*F90"` . || exit 7
         cd      ../..
      endif
   else
      echo "ERROR - DART_params.csh use_SourceMods = ${use_SourceMods}"
      echo "ERROR - but there are no SourceMods in ${SourceModDir}"
      echo "        See discussion in DART_params.csh for information on"
      echo "        where to get a tar file of SourceMods for DART." 
      exit 7
   endif
endif

${BUILD_WRAPPER} ./case.build || exit 9

# ==============================================================================
# What to do next
# ==============================================================================

cat << EndOfText >! CESM_instructions.txt

-------------------------------------------------------------------------
Time to check the case.

1) cd ${rundir}
   and check the compatibility between the namelists/pointer files
   and the files that were staged.

2) cd ${caseroot}

3) check things

4) run a single job (and send mail), verify that it works without assimilation
   ./case.submit -M all

5) IF NEEDED, compile all the DART executables by
   cd  ${dartroot}/models/clm/work
   ./quickbuild.sh

6) Modify the case to enable data assimilation and
   run DART by executing
   cd ${caseroot}
   ./CESM_DART_config
   and follow the directions.

7) Make sure the DART-related parts are appropriate.
   Check the input.nml
   Check the assimilate.csh or perfect_model.csh - as appropriate
   ./case.submit -M all

8) If that works
   ./xmlchange CONTINUE_RUN=TRUE
   ./xmlchange RESUBMIT=<number_of_cycles_to_run>
   and
   ./case.submit -M all

-------------------------------------------------------------------------

EndOfText

cat CESM_instructions.txt

exit 0

