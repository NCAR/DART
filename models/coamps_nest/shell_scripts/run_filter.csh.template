#!/bin/tcsh
#
# DART software - Copyright UCAR. This open source software is provided
# by UCAR, "as is", without charge, subject to all terms of use at
# http://www.image.ucar.edu/DAReS/DART/DART_download
#
# DART $Id: run_filter.csh.template 11611 2017-05-05 23:10:55Z thoar@ucar.edu $
#
# This script performs an assimilation on a collection of coamp hdf5 files.
# This script presumes/requires that coamps has exactly two nests and that
# all the variables for both nests are in the same hdf5 file.
#
# The prerequisite for this script is that setup_experiment.csh has been run.
# setup_experiment.csh replaces a dummy string with the correct experiment
# directory.
#
#==========================================================================
# SLURM directives                      sbatch advance_ensemble.csh
#                                       squeue -u $USER
#                                       scancel <jobnumber>
#SBATCH --ignore-pbs
#SBATCH --job-name=filter
#SBATCH --output=filter-%A.log
#SBATCH --error=filter-%A.err
#SBATCH --ntasks=48
#SBATCH --ntasks-per-node=16
#SBATCH --time=00:30:00
#SBATCH --error=filter-%A.err
#SBATCH --output=filter-%A.log
#
#==========================================================================
# PBS directives                        qsub test_batch.csh
#                                       qstat -u $USER
#                                       qdel <jobnumber>
#PBS -N filter
#PBS -e filter.err
#PBS -o filter.log
#PBS -l select=3:ncpus=16:mpiprocs=16
#PBS -l walltime=00:30:00
#PBS -A P8685nnnn
#PBS -q economy
#PBS -r n
#
#==========================================================================
# LSF directives                        bsub < advance_ensemble.csh
#                                       bjobs
#                                       bkill <jobnumber>
#BSUB -J filter
#BSUB -o filter.%J.log
#BSUB -P P8685nnnn
#BSUB -q regular
#BSUB -n 48
#BSUB -R "span[ptile=16]"
#BSUB -W 0:30
#BSUB -N -u ${USER}@ucar.edu
#
#==========================================================================

if ($?SLURM_JOB_ID) then

   set ORIGINALDIR = $SLURM_SUBMIT_DIR
   set     JOBNAME = $SLURM_JOB_NAME
   set       JOBID = $SLURM_JOBID
   set     MYQUEUE = $SLURM_JOB_PARTITION
   set      MYHOST = $SLURM_SUBMIT_HOST
   set   LAUNCHCMD = "mpirun -np $SLURM_NTASKS -bind-to core"

else if ($?PBS_O_WORKDIR) then

   set ORIGINALDIR = $PBS_O_WORKDIR
   set     JOBNAME = $PBS_JOBNAME
   set       JOBID = $PBS_JOBID
   set      MYHOST = $PBS_O_HOST
   set     MYQUEUE = $PBS_QUEUE
   set   LAUNCHCMD = "mpiexec_mpt"

else if ($?LS_SUBCWD) then

   set ORIGINALDIR = $LS_SUBCWD
   set     JOBNAME = $LSB_JOBNAME
   set       JOBID = $LSB_JOBID
   set     MYQUEUE = $LSB_QUEUE
   set      MYHOST = $LSB_SUB_HOST
   set   LAUNCHCMD = "mpirun.lsf"

else

   set ORIGINALDIR = `pwd`
   set     JOBNAME = filter
   set       JOBID = $$
   set     MYQUEUE = Interactive
   set      MYHOST = `hostname`
   set   LAUNCHCMD = ""

endif

#--------------------------------------------------------------------------
# Just an echo of job attributes
#--------------------------------------------------------------------------

echo
echo "${JOBNAME} ($JOBID) submit directory ${ORIGINALDIR}"
echo "${JOBNAME} ($JOBID) submit      host ${MYHOST}"
echo "${JOBNAME} ($JOBID) running in queue ${MYQUEUE}"
echo "${JOBNAME} ($JOBID) started at "`date`
echo

cd EXPERIMENT_DIRECTORY

#==========================================================================
# STEP 1: prepare for DART INFLATION
# This stages the files that contain the inflation values.
# The inflation values change through time and should be archived.
# The strategy is to use the LATEST (last) inflation file.
#
# This file is only relevant if 'inflation' is turned on -
# i.e. if inf_flavor(:) /= 0 AND inf_initial_from_restart = .TRUE.
#
# filter_nml
# inf_flavor                  = 2,                 0,
# inf_initial_from_restart    = .true.,            .false.,
#
# 'create_ensemble.csh' creates inflation files with decent starting values.
# Consequently, we can always set 'inf_initial_from_restart' to .true.
#==========================================================================

# These are used to determine IF we are doing inflation.

set  MYSTRING = `grep 'inf_flavor' input.nml`
set  MYSTRING = `echo $MYSTRING | sed -e "s#[=,'\.]# #g"`
set  PRIOR_INF = $MYSTRING[2]
set  POSTE_INF = $MYSTRING[3]

# IFF we want PRIOR inflation:

if ( $PRIOR_INF > 0 ) then
      # Using prior inflation mean files from the previous assimilation.
      # One per nest (aka DART 'domain')
      mv output_priorinf_mean_d01.nc input_priorinf_mean_d01.nc || exit 1
      mv output_priorinf_mean_d02.nc input_priorinf_mean_d02.nc || exit 1
      mv output_priorinf_sd_d01.nc   input_priorinf_sd_d01.nc   || exit 1
      mv output_priorinf_sd_d02.nc   input_priorinf_sd_d02.nc   || exit 1
else
   echo "Prior Inflation           not requested for this assimilation."
endif

# IFF we want POSTERIOR inflation:

if ( $POSTE_INF > 0 ) then
      # Using posterior inflation mean files from the previous assimilation.
      # One per nest (aka DART 'domain')
      mv output_postinf_mean_d01.nc input_postinf_mean_d01.nc || exit 1
      mv output_postinf_mean_d02.nc input_postinf_mean_d02.nc || exit 1
      mv output_postinf_sd_d01.nc   input_postinf_sd_d01.nc   || exit 1
      mv output_postinf_sd_d02.nc   input_postinf_sd_d02.nc   || exit 1
else
   echo "Posterior Inflation       not requested for this assimilation."
endif

#==========================================================================
# STEP 2:  Get the DART observation sequence file.
#==========================================================================

# Remove the last set of DART run-time logs - if they exist.
\rm -f dart_log.out dart_log.nml

# grab the CDTG from someplace 
set CDTGSTRING = `grep cdtg convert.nml | grep -oE '[[:digit:]]+'`
set CDTG = $CDTGSTRING[1]

if ( -e obs_seq_${CDTG}.out ) then 
   \ln -sf obs_seq_${CDTG}.out obs_seq.out
else
   echo "ERROR: expecting to find obs_seq_${CDTG}.out ... exiting."
   exit 2
endif

#TJH if coamps creates FGAT observations, they will need to be converted
#TJH to DART format. Here is some pseudo-code based on ROMS:
#TJH set OBS_ROOT = $MODname:r
#TJH 
#TJH # Because convert_coamps_obs and filter need bits from the coamps model_mod,
#TJH # a (single) coamps input file is required to satisfy 'static_init_model()'.
#TJH # Any one will do.
#TJH 
#TJH #ln -sf instance_0001/coamps_posterior_???_${OCEAN_TIME}.nc MyDAINAME
#TJH ln -sf instance_0001/coamps_posterior_???_${CDTG}.nc MyDAINAME
#TJH 
#TJH #ls -1 instance_*/${OBS_ROOT}*_${OCEAN_TIME}.nc  >! precomputed_files.txt
#TJH ls -1 instance_*/${OBS_ROOT}*_${CDTG}.nc  >! precomputed_files.txt
#TJH 
#TJH ./innov_to_obs_seq  || exit 2

#==========================================================================
# STEP 3: Create netCDF files with the DART state from the HDF5 files
#==========================================================================

@ instance = 0
foreach INSTANCE_DIRECTORY ( instance_??? )
   @ instance++

   cd ${INSTANCE_DIRECTORY}

   set HDFFILE = `printf      coamps_%03d_${CDTG}.hdf5 $instance`
   set  NCFILE = `printf dart_vector_%03d_${CDTG}.nc   $instance`

   if ( -e    ${HDFFILE} ) then
      \ln -sf ${HDFFILE} coamps.hdf5
   else
      echo "ERROR: No coamps file ${HDFFILE} ... exiting"
      exit 3
   endif

   # This is slow and should be done in parallel 

   ../trans_coamps_to_dart || exit 3

   \mv dart_vector.nc ${NCFILE}
   cd ..

end

#==========================================================================
# STEP 4:  Then we run DART on the ensemble of new states
#
# collect all the coamps_RESTARTs into a list of input files for filter
# The io module will error out if the file_list_domain_N.txt is too short.
# (make sure all instances of coamps advanced successfully)
#==========================================================================

ls -1 instance_*/dart_vector_???_${CDTG}.nc  >! file_list_domain_1.txt
ls -1 instance_*/dart_vector_???_${CDTG}.nc  >! file_list_domain_2.txt

# filter needs files to read variables sizes, etc.

\rm -f coamps.hdf5 dart_vector.nc
\ln -s instance_001/coamps_001_${CDTG}.hdf5    coamps.hdf5    || exit 4
\ln -s instance_001/dart_vector_001_${CDTG}.nc dart_vector.nc || exit 4

${LAUNCHCMD} ./filter || exit 4

# Tag the output with the valid time of the model state.

foreach FILE ( input_*mean.nc     input_*sd.nc \
            preassim_*mean.nc  preassim_*sd.nc \
           postassim_*mean.nc postassim_*sd.nc \
            analysis_*mean.nc  analysis_*sd.nc \
              output_*mean.nc    output_*sd.nc \
           preassim_member_???.nc \
           postassim_member_???.nc )

   if (  -e $FILE ) then
      set FEXT  = $FILE:e
      set FBASE = $FILE:r
      \mv -v $FILE ${FBASE}.${CDTG}.${FEXT}
   else
      echo "$FILE does not exist, no need to take action."
   endif

end

# Tag the observation file with the valid time of the model state.

\mv -v obs_seq.final             obs_seq.final.${CDTG}

#==========================================================================
# STEP 5: Update the hdf5 files with the information in the updated netCDF files
#
# 'trans_dart_to_coamps' uses COAMPS write routines that expect a DTG in
# the file name, the dart call provides the base filename of 'CoampsUpdate'
#==========================================================================

@ instance = 0
foreach INSTANCE_DIRECTORY ( instance_??? )
   @ instance++

   cd ${INSTANCE_DIRECTORY}

   set  NCFILE = `printf dart_vector_%03d_${CDTG}.nc    $instance`
   set HDFFILE = `printf      coamps_%03d_${CDTG}.hdf5  $instance`
   set NEWFILE = CoampsUpdate_${CDTG}.hdf5

   unlink dart_vector.nc coamps.hdf5
   ln -sf $NCFILE  dart_vector.nc || exit 5
   ln -sf $HDFFILE coamps.hdf5    || exit 5

   ../trans_dart_to_coamps || exit 5

   # what do we want to name the updated file ...
   \mv $HDFFILE $NEWFILE

   cd ..

end

echo "${JOBNAME} ($JOBID) finished at "`date`

exit 0

# <next few lines under version control, do not edit>
# $URL: https://svn-dares-dart.cgd.ucar.edu/DART/branches/coamps/models/coamps/shell_scripts/run_filter.csh.template $
# $Revision: 11611 $
# $Date: 2017-05-05 16:10:55 -0700 (Fri, 05 May 2017) $
